<!DOCTYPE html>
<html>
<head></head>
<body>    

<h1>Audio-to-text webapp</h1>
<ol type="A">
	<li>Select a model to transcribe audio files.</li>
	<li>Upload an audio file</li>
  	<li>View an audio file [audio display].</li>
	<li>Transcribe audio files.</li>
	<li>Copy paste the transcribed text!</li>
</ol>

<!-- ---------------------------------------- -->
<hr>
<!-- ---------------------------------------- -->
<!-- View two split window -->
<div align="left">
<table style='text-align: left; width: 300px; display:block'>
<tr>
        
<th id="inputs">

<h3>A. Select a model to transcribe audio files</h3>
<fieldset>
<input type="radio" id="openai" name="radio_name0" value="openai" />
<label for="openai">OpenAI Whisper</label>
<br>
<input type="radio" id="custom_model" name="radio_name0" value="custom_model" />
<label for="custom_model">Custom Model</label>
</fieldset>
<br>
<label for="enter_key" id="enter_key" style="display:none">Enter OpenAI Key:</label>
<input id="API_KEY" type="text" value="" placeholder="OPENAI_API_KEY" rows="10" cols="100" style="display:none; text-align: left; width: 150px;">
<br>
	
<h3>B. Upload an audio file</h3>
<input id="file_name" type="text" value="" placeholder="file_name" rows="10" cols="100" style="display:none; text-align: left; width: 600px;">
<input id="file_download_url" type="text" value="" placeholder="file_download_url" rows="10" cols="100" style="display:none; text-align: left; width: 600px;">
<input type="file" id="upload_file" accept="audio/*" style="display:block">
<br>

<h3>C. View an audio file [audio display]</h3>
<!-- <audio controls id="audio_input_display" style="display:none"><source id="audio_source_input_display" src="" type="audio/mpeg"></audio> -->
<audio controls id="audio_input_display" style="display:none"></audio>
	
<br>

<h3>D. Transcribe audio files</h3>
<button id="transcribe_audio" onclick="transcribe_audio()" style="display:block">Transcribe audios</button>

</th>
	
<!-- ---------------------------------------- -->

<th id="outputs">
<div id="notification"></div>
<div id="error"></div>
</th>
	
</tr>
</table>
</div>  
	
<!-- ---------------------------------------- -->
<!-- CSS -->
<style>
div { padding: 10px; display:block; font-family:courier; font-size:15px; height:300px; }
	
div#notification { position: relative; color: #3236a8; }
div#error { position: relative; color: #bd1f17; }

table {vertical-align: top; border-collapse: collapse; position: relative; z-index: 0; border: 0px solid black;}

tr {vertical-align: top; border: 0px solid black; padding: 10px 10px; width: 800px; }

th, td {vertical-align: top; border: 0px solid black; padding: 10px; width: 800px; }
th#inputs {width: 500px; }
th#outputs {width: 800px; }
</style>
	
<!-- --------------------------------------------------- -->
	  

	  
<script>

var model_name = "";
var API_KEY = "";
var max_loops = 10;

			

// ----------------------------------------------------

// The eventlistener needs to be always running, to detect which file the user selected with browse
document.getElementById("upload_file").addEventListener("change", previewInput, false);

var audioElement = document.getElementById("audio_input_display");
var audioContext = {};

async function previewInput(event) {
	
	// ---------------------
	
	// console.log("event :", event);

	// ---------------------
	
	// Take the first file
	const file = event.target.files[0];  // first file in the list of selected files, better for selecting multiple files at one time
	// console.log("file :", file);

	// ---------------------
	
	// Set the file name
	document.getElementById("file_name").value = file.name;
	document.getElementById('file_name').placeholder = file.name;

	// ---------------------

	const reader = new FileReader();
	
	reader.onload = async function(e){

		// Print base64_string
		// console.log("e.target.result :", e.target.result);

		// ---------------------
		
		await fetch(e.target.result)
			.then(response => response.arrayBuffer())
			.then(async function(arraybuffer) {
				    
				    // ----------------------------
				    
				    // Print arraybuffer
				    console.log("arraybuffer:", arraybuffer);

				    // ----------------------------

				    // Create the audio context
				    audioContext = new AudioContext();

				    // ----------------------------

				    // Decode the arraybuffer - *** this should be the audio data to play ***
				    return audioContext.decodeAudioData(arraybuffer);
			    })
			.then(async function(decoded_arraybuffer) {

				console.log("decoded_arraybuffer:", decoded_arraybuffer);
				
				// ----------------------------

				    // Create the audio source
				    var source = audioContext.createMediaElementSource(audioElement);

				    // OR
				    
				    // var source = audioContext.createBufferSource(audioElement);
				    
				    // ----------------------------
				    
				    // Set the file_download_url
				    // Put the text data in a temporary blob file, and create a url to the data
				    const blob = new Blob([decoded_arraybuffer], { type: file.type });
				    
				    // Create a url for the data object
				    const url = URL.createObjectURL(blob);
				    document.getElementById("file_download_url").value = url;
				    document.getElementById('file_download_url').placeholder = url;

				    // ----------------------------

				    // Assign source variables
				    
				    // [0] Set the audio source to play the audio file
				    // Way 0: base64 string encoded - does not make sense because is base64 encrypted, it is not an mp3
				    // source.src = e.target.result;
				    
				    // Way 1: blob url of decoded_arraybuffer
				    // url = "blob:https://codesolutions2.github.io/1d0872b3-73c9-4941-9cf5-a95b71f57bd9"
				    // source.src = url;  // no audio file could be played
				    
				    // Way 2: try decoded_arraybuffer directly
				    // source.src = decoded_arraybuffer;	// no audio file could be played

				    // Way 3: audio file name
				    source.src = document.getElementById("file_name").value  // it will think the file is in the GitHub repository

				    // [1] 
				    source.buffer = decoded_arraybuffer;

				    // [2]
				    source.id = "audio_source";

				    // [3]
				    source.type = file.type;

				    // ----------------------------
				    
				    console.log("source:", source);

				    // ----------------------------

				    // Did nothing 
				    source.connect(audioContext.destination);
				    // console.log("source after destination:", source);
			})
			        
			    
		
		    // Try 2: 
		    // await fetch(e.target.result)
		    //   .then(response => response.blob())
		    //   .then(async function(blob_object) { 
					// Transform blob into a file
				// 	return new File ([blob_object], file_object.name, {type: "audio/mp3"});
				// })
		
    
	}
	reader.readAsDataURL(file);  // for Try 0, 1, 2
  	// reader.readAsArrayBuffer(file);  // for Try 3
}


	
// ----------------------------------------------------
	
async function processEvent_openai(event) {
	if (this.getAttribute("checked") == false) {
		document.getElementById("enter_key").style.display = "none";
		document.getElementById("API_KEY").style.display = "none";
	} else  {
		document.getElementById("enter_key").style.display = "block";
		document.getElementById("API_KEY").style.display = "block";
	}
}

async function processEvent_custom_model(event) {
	if (this.getAttribute("checked") == false) {
		document.getElementById("enter_key").style.display = "none";
		document.getElementById("API_KEY").style.display = "none";
	} else  {
		document.getElementById("enter_key").style.display = "none";
		document.getElementById("API_KEY").style.display = "none";
	}
}
	
document.getElementById("openai").addEventListener("click", processEvent_openai, false);
document.getElementById("custom_model").addEventListener("click", processEvent_custom_model, false);

// ----------------------------------------------------


async function transcribe_audio() {

	return await new Promise(r => setTimeout(r, 10))
		// A. Select a model to transcribe audio files
		.then(async function() {
			const openai = document.getElementById("openai").checked;
			const custom_model = document.getElementById("custom_model").checked;
	
			if (openai == true && custom_model == false) {
				model_name = 'openai';
				API_KEY = document.getElementById("API_KEY").value;
			}
			
			if (openai == false && custom_model == true) {
				model_name = 'custom_model';
			}
			
			if (openai == false && custom_model == false) {
				document.getElementById('error').innerHTML += "Select a model.";
			}
			
			console.log("model_name: ", model_name);
			// console.log("API_KEY: ", API_KEY);
			return [model_name, API_KEY];
		})
		// B. Input one or more audio files: [Option from GitHub] OR [Option upload]
		.then(async function(array) {

			// Try to get the audio file from the DOM
			console.log("audio: ", document.getElementById("audio_input_display"))

			console.log("audioElement source: ", document.getElementById("audio_input_display")).getElementsByTagName("source")[0];
			
			// Insert the audio file information into the dictionary
			total_file_objects = [[{name: document.getElementById("file_name").value, 
						file_download_url: document.getElementById("file_download_url").value, 
						audio_data: ""} ]];			

			console.log("total_file_objects: ", total_file_objects);
			
			// ----------------------------------------------------
			
			return {total_file_objects: total_file_objects, model_name: array[0], API_KEY: array[1], index: 0};
		})
		// C. View an audio file [audio display]
		.then(async function(dict_out) { 

			// Make the audio player visible
			document.getElementById("audio_input_display").style.display = "block"; 

			return dict_out;
		})
		// D. Transcribe audio files
		// .then(async function(dict_out) {
		//  	console.log("dict_out['total_file_objects']:", dict_out['total_file_objects']);
			
		//  	const total_files = dict_out['total_file_objects'][0].length;
		//  	console.log("total_files :", total_files);
		//  	console.log("dict_out['index'] :", dict_out['index']);
		//  	console.log("total_files-1 :", total_files-1);
		//  	console.log("max_loops :", max_loops);
			
		//  	while (dict_out['index'] < total_files && dict_out['index'] < max_loops) {
		// 		if (dict_out['model_name'] == 'openai') {
		//  			await call_openai_model(dict_out['total_file_objects'][0][dict_out['index']], dict_out['API_KEY'])
		//  				.then(async function() { await new Promise(r => setTimeout(r, 5000)); })
		//  		} else {
		//  			await call_custom_model(dict_out['total_file_objects'][0][dict_out['index']])
		//  				.then(async function() { await new Promise(r => setTimeout(r, 5000)); })
		//  		}
		//  		dict_out['index'] = dict_out['index'] + 1;
		//  	}
		// })
		.catch(error => { document.getElementById('error').innerHTML += error; });
		
}


// ----------------------------------------------------


async function call_custom_model(file_object) {

	document.getElementById('error').innerHTML = 'Model is in development';
}

	
// ----------------------------------------------------

async function start_processing_notification() {
	// Processing information
	document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + 'Processing audio\n';
}

// ----------------------------------------------------




async function call_openai_model(file_object, OPENAI_API_KEY) {
	
	await start_processing_notification()
		// Way 0: fetch data from pc (base64 string encoded) - arraybuffer - decode arraybuffer - create blob of decode arraybuffer - obtain url of blob (file_download_url)
		.then(async function() { return await fetch(document.getElementById("file_download_url").value); })
		.then(response => response.blob())
		// OR
		// Way 1: Create a blob from the arrayBuffer
		// .then(() => { return new Blob(file_object.audio_data, {type: "audio/mp3"}); })
		// -------------------------------------
		// Transform blob into a file
		.then(async function(blob_object) { 
			return new File ([blob_object], file_object.name, {type: "audio/mp3"});
		})
		.then(async function(file_blob_object) { 
			// Use transcription or translation model randomly
		 	if (Math.floor(Math.random()*2) == 1) {
		 		await openai_transcription(file_blob_object, 'file_blob_object', file_object.name, OPENAI_API_KEY);
		 	} else {
		 		await openai_translation(file_blob_object, 'file_blob_object', file_object.name, OPENAI_API_KEY);
		 	}
		})
		.then(async function() { document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + '\n\nTranscription Processing Done'; })
		.catch(error => { document.getElementById('error').innerHTML = error; });
}

// ----------------------------------------------------


async function openai_transcription(file_input, which_input, header_string, OPENAI_API_KEY) {
	
	const url = 'https://api.openai.com/v1/audio/transcriptions';

	const headers = new Headers();
	headers.append("Authorization", 'Bearer ' + OPENAI_API_KEY);
	headers.append("Accept", "application/json");
	
	const formData = new FormData();
	if (which_input == 'blob_object') {
		formData.append("file", file_input);
	} else {
		// using a file_blob_object
		formData.append("file", file_input, header_string); // mp3, mp4, mpeg, mpga, m4a, wav, or webm
	}
	formData.append("model", "whisper-1");
	formData.append("prompt", "Transcribe the audio");  // Style context for the transcription
	formData.append("response_format", "text");  // json, text, srt, verbose_json, or vtt
	formData.append("temperature", "0");  // The sampling temperature, between 0 (accurate) and 1 (random response)
	formData.append("language", "en");
	formData.append("transcription", "plain text"); // plain text, srt, vtt
	
	const options = {method: 'POST', 
		       headers: headers, 
		       body: formData,
		       redirect: "follow"
		      };
	
	// Print text part of JSON response only with user message
	await fetch(url, options)
		.then(response => response.text())
		.then(async function(result) { 
			document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + `openai_transcription\n${header_string}\n\n${result}\n\n`; 
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}


// ----------------------------------------------------

	
async function openai_translation(file_input, which_input, header_string, OPENAI_API_KEY) {
	
	const url = 'https://api.openai.com/v1/audio/translations';

	const headers = new Headers();
	headers.append("Authorization", 'Bearer ' + OPENAI_API_KEY);
	headers.append("Accept", "application/json");
	
	const formData = new FormData();
	if (which_input == 'blob_object') {
		formData.append("file", file_input);
	} else {
		// using a file_blob_object
		formData.append("file", file_input, header_string); // mp3, mp4, mpeg, mpga, m4a, wav, or webm
	}
	formData.append("model", "whisper-1");
	formData.append("prompt", "Transcribe the audio");  // Style context for the transcription
	formData.append("response_format", "text");  // json, text, srt, verbose_json, or vtt
	formData.append("temperature", "0");  // The sampling temperature, between 0 (accurate) and 1 (random response)
	formData.append("language", "en");
	formData.append("transcription", "plain text"); // plain text, srt, vtt
	
	const options = {method: 'POST', 
		       headers: headers, 
		       body: formData,
		       redirect: "follow"
		      };
	
	// Print text part of JSON response only with user message
	return await fetch(url, options)
		.then(response => response.text())
		.then(async function(result) { 
			document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + `openai_translation\n${header_string}\n${result}\n\n`; 
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}

	
// ----------------------------------------------------
	

async function get_one_audio_file_object_from_repo(repoOwner, repoName, file_name) {

	var url = `https://api.github.com/repos/${repoOwner}/${repoName}/contents`;

	let file_objects = [];
	
	return await fetch(url)
		.then(res => res.json())
		.then(data => {
			data.forEach(async function(file) {
				var regexp = new RegExp(`${file_name}`, 'g');
				if (file.type === 'file' && file.name.match(regexp)) {
					file_objects.push(file);
				}
			});
			return file_objects;
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}


// ----------------------------------------------------


async function get_audio_file_objects_from_repo(repoOwner, repoName) {

	var url = `https://api.github.com/repos/${repoOwner}/${repoName}/contents`;
	
	var file_objects = [];
	
	return await fetch(url)
		.then(res => res.json())
		.then(data => {
			data.forEach(async function(file) {
				if (file.type === 'file' && file.name.match(/.(mp3)$/i)) {
					file_objects.push(file);
				}
			});
			return file_objects;
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}


// ----------------------------------------------------
	
</script>

  </body>
</html>
