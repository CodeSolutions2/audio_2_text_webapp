<!DOCTYPE html>
<html>
<head></head>
<body>    

<h1>Audio-to-text webapp</h1>
<ol type="A">
  <li>Select a model to transcribe audio files.</li>
	<li>Input one or more audio files: [Option from GitHub] OR [Option upload].</li>
  	<li>View an audio file [audio display].</li>
	<li>Transcribe audio files.</li>
	<li>Copy paste the transcribed text!</li>
</ol>

<!-- ---------------------------------------- -->
<hr>
<!-- ---------------------------------------- -->
<!-- View two split window -->
<div align="left">
<table style='text-align: left; width: 300px; display:block'>
<tr>
        
<th id="inputs">

<h3>A. Select a model to transcribe audio files</h3>
<fieldset>
<input type="radio" id="openai" name="radio_name1" value="openai" />
<label for="openai">OpenAI Whisper</label>
<br>
<input type="radio" id="custom_model" name="radio_name1" value="custom_model" />
<label for="custom_model">Custom Model</label>
</fieldset>
<br>
<label for="enter_key" id="enter_key" style="display:none">Enter OpenAI Key:</label>
<input id="API_KEY" type="text" value="" placeholder="OPENAI_API_KEY" rows="10" cols="100" style="display:none; text-align: left; width: 150px;">

<br>

<h3>B. Input one or more audio files: [Option from GitHub] OR [Option upload]</h3>
<h4>[Option from GitHub] A list of audio urls from a GitHub repository, a GitHub repository url</h4>
<p id="audio_repo_instructions" style="display:block">For example, GitHub repository url: https://github.com/CodeSolutions2/audio_2_text_webapp. For example, list of audio urls: https://github.com/CodeSolutions2/audio_2_text_webapp/test.mp3, https://github.com/CodeSolutions2/audio_2_text_webapp/test1.mp3</p>
<input id="audio_url" type="text" value="" placeholder="audio_url" rows="10" cols="100" style="display:block; text-align: left; width: 600px;">
<h4>[Option upload] Upload an audio</h4>
Use the Browse button to select an audio, then click 'Confirm audio selection' to confirm the selection.
<br>
<input type="file" id="file_input" accept="audio/*" style="display:block">
<br>

<h3>C. View an audio file [audio display]</h3>
<audio controls id="audio_input_display" style="display:none"><source id="audio_source_input_display" type="audio/mpeg"></audio>
	
<br>

<h3>D. Transcribe audio files</h3>
<button id="transcribe_audios" onclick="transcribe_audios_version2()" style="display:block">Transcribe audios</button>

</th>
	
<!-- ---------------------------------------- -->

<th id="outputs">
<div id="notification"></div>
<div id="error"></div>
<div id="file_object_name" style="display:none"></div>
<div id="option1_information" style="display:none"></div>
</th>
	
</tr>
</table>
</div>  
	
<!-- ---------------------------------------- -->
<!-- CSS -->
<style>
div { padding: 10px; display:block; font-family:courier; font-size:15px; height:300px; }
	
div#notification { position: relative; color: #3236a8; }
div#error { position: relative; color: #bd1f17; }

table {vertical-align: top; border-collapse: collapse; position: relative; z-index: 0; border: 0px solid black;}

tr {vertical-align: top; border: 0px solid black; padding: 10px 10px; }

th, td {vertical-align: top; border: 0px solid black; padding: 10px; }
th#inputs {width: 100%; }
th#outputs {width: 800px; }
</style>
	
<!-- --------------------------------------------------- -->
	  

	  
<script>

var model_name = "";
var API_KEY = "";
var max_loops = 10;

// ----------------------------------------------------

// document.getElementById("audio_repo").addEventListener("click", processEvent_audio_input_repo, false);
// document.getElementById("audio_input").addEventListener("click", processEvent_audio_input_upload, false);

// async function processEvent_audio_input_repo(event) {

// 	document.getElementById("audio_input_display").style.display = "none";
	
// 	if (this.getAttribute("checked") == false) {
// 		document.getElementById("audio_repo_instructions").style.display = "none";
// 		document.getElementById("audio_url").style.display = "none";
// 	} else  {
		
// 		document.getElementById("audio_repo_instructions").style.display = "block";
// 		document.getElementById("audio_url").style.display = "block";
// 	}
// }
	
// async function processEvent_audio_input_upload(event) {

	// This looks useless, but to restart it from the a used state this would reset the settings
// 	document.getElementById("audio_input_display").style.display = "none";
// 	document.getElementById("audio_repo_instructions").style.display = "none";
// 	document.getElementById("audio_url").style.display = "none";
	
// 	if (this.getAttribute("checked") == true) {
//     document.getElementById("file_input").addEventListener("change", previewInput, false);
// 	}
// }

// ----------------------------------------------------

// The eventlistener needs to be always running, to detect which file the user selected with browse
document.getElementById("file_input").addEventListener("change", previewInput, false);

async function previewInput(event) {
	
	// ---------------------
	
	// console.log("event :", event);

	// ---------------------
	
	// Take the first file
	const file = event.target.files[0];  // first file in the list of selected files, better for selecting multiple files at one time
	// console.log("file :", file);
	
	document.getElementById('option1_information').innerHTML = file.name + ',' + event.target.value;

	// ---------------------

	const reader = new FileReader();
	reader.onload = function(e){
		//console.log("e.target.result :", e.target.result);
		document.getElementById('audio_source_input_display').src = e.target.result; // the base64_string of the audio file
	}
	reader.readAsDataURL(file);
}

// ----------------------------------------------------
	
async function processEvent_openai(event) {
	if (this.getAttribute("checked") == false) {
		document.getElementById("enter_key").style.display = "none";
		document.getElementById("API_KEY").style.display = "none";
	} else  {
		document.getElementById("enter_key").style.display = "block";
		document.getElementById("API_KEY").style.display = "block";
	}
}

async function processEvent_custom_model(event) {
	if (this.getAttribute("checked") == false) {
		document.getElementById("enter_key").style.display = "none";
		document.getElementById("API_KEY").style.display = "none";
	} else  {
		document.getElementById("enter_key").style.display = "none";
		document.getElementById("API_KEY").style.display = "none";
	}
}
	
document.getElementById("openai").addEventListener("click", processEvent_openai, false);
document.getElementById("custom_model").addEventListener("click", processEvent_custom_model, false);

// ----------------------------------------------------


async function transcribe_audios_version2() {

	return await new Promise(r => setTimeout(r, 10))
		// A. Select a model to transcribe audio files
		.then(async function() {
			const openai = document.getElementById("openai").checked;
			const custom_model = document.getElementById("custom_model").checked;
	
			if (openai == true && custom_model == false) {
				model_name = 'openai';
				API_KEY = document.getElementById("API_KEY").value;
			}
			
			if (openai == false && custom_model == true) {
				model_name = 'custom_model';
			}
			
			if (openai == false && custom_model == false) {
				document.getElementById('error').innerHTML += "Select a model.";
			}
			
			console.log("model_name: ", model_name);
			// console.log("API_KEY: ", API_KEY);
			return [model_name, API_KEY];
		})
		// B. Input one or more audio files: [Option from GitHub] OR [Option upload]
		.then(async function(array) {
			// user will give:
			// https://github.com/repoOwner/repoName
			// OR
			// https://github.com/repoOwner/repoName/audio_file0.mp3, https://github.com/repoOwner/repoName/audio_file1.mp3

			// ----------------------------------------------------
			// Check if [Option from GitHub] or [Option upload] fields are checked
			// ----------------------------------------------------
			var user_input = document.getElementById("audio_url").value;
			console.log("user_input: ", user_input);
			
			let total_file_objects = {};
			let input_file_type = "";
			
			if (user_input.length == 0 && document.getElementById('audio_source_input_display').src.length > 0) {
				let text = document.getElementById('option1_information').innerHTML;
				let text_arr = text.split(',');
				let filename = text_arr.at(0);
				let file_download_url = text_arr.at(1);
				total_file_objects = [[{0: {name: filename, download_url: file_download_url, base64_string: document.getElementById('audio_source_input_display').src} }]];
				input_file_type = "option1";
			}
			
			if (user_input.length > 0 && document.getElementById('audio_source_input_display').src.length == 0) {
				total_file_objects = await process_user_input_repoFiles(user_input);
				input_file_type = "option0";
			}
			
			if (user_input.length == 0 && document.getElementById('audio_source_input_display').src.length == 0) {
				document.getElementById('error').innerHTML += "No input methods are selected. Select an audio file input method: [Option from GitHub] or [Option upload].";
			}

			if (user_input.length > 0 && document.getElementById('audio_source_input_display').src.length > 0) {
				document.getElementById('error').innerHTML += document.getElementById('error').innerHTML + "Both input methods are selected. Select an audio file input method: [Option from GitHub] or [Option upload].";
			}

			console.log("total_file_objects: ", total_file_objects);
			
			// ----------------------------------------------------
			
			return {total_file_objects: total_file_objects, model_name: array[0], API_KEY: array[1], index: 0, input_file_type: input_file_type};
		})
		// C. View an audio file [audio display]
		.then(async function(dict_out) { 
			document.getElementById("audio_input_display").style.display = "block"; 

			// Specify which source audio to play
			if (document.getElementById('audio_source_input_display').src.length == 0) {
				// It is the GitHub repository method
				// Select the first file from the list
				document.getElementById('audio_source_input_display').src = dict_out['total_file_objects'][0][0].download_url;
			}
			return dict_out;
		})
		// D. Transcribe audio files
		.then(async function(dict_out) {
			console.log("dict_out['total_file_objects']:", dict_out['total_file_objects']);
			
			const total_files = dict_out['total_file_objects'][0].length;
			console.log("total_files :", total_files);

			console.log("dict_out['index'] :", dict_out['index']);
			console.log("total_files-1 :", total_files-1);
			console.log("max_loops :", max_loops);
			
			while (dict_out['index'] < total_files && dict_out['index'] < max_loops) {
				
				if (dict_out['model_name'] == 'openai' && dict_out["input_file_type"] == "option0") {
					await call_openai_model_option0(dict_out['total_file_objects'][0][dict_out['index']], dict_out['API_KEY'])
						.then(async function() { await new Promise(r => setTimeout(r, 5000)); })
				} else if (dict_out['model_name'] == 'openai' && dict_out["input_file_type"] == "option1") {
					await call_openai_model_option1(dict_out['total_file_objects'][0][dict_out['index']], dict_out['API_KEY'])
						.then(async function() { await new Promise(r => setTimeout(r, 5000)); })
				} else {
					await call_custom_model(dict_out['total_file_objects'][0][dict_out['index']])
						.then(async function() { await new Promise(r => setTimeout(r, 5000)); })
				}
				
				dict_out['index'] = dict_out['index'] + 1;
				// console.log("dict_out['index']:", dict_out['index']);
			}
		})
		//.catch(error => { document.getElementById('error').innerHTML += error; });
		
}



// ----------------------------------------------------


async function process_user_input_repoFiles(user_input) {

	// Obtain a list of file_objects
	let total_file_objects = [];
	
	// look for .mp3, .wav in string
	if (user_input.match(/.(mp3)$/i) || user_input.match(/.(wav)$/i)) {

		console.log("String of file urls:");
		
		// user entered a repository file_name
		var array_of_file_names = user_input.split(",");

		array_of_file_names.forEach(async function(file_url, index) {

			// user entered a repository url only
			let url_split = file_url.split("/");
			console.log("url_split:", url_split);
		
			// take last two values of url_split
			let file_name = url_split.pop();
			let repoName = url_split.pop();
			let repoOwner = url_split.pop();
			console.log("file_name:", file_name);
			console.log("repoName:", repoName);
			console.log("repoOwner:", repoOwner);
			
			let out = await get_one_audio_file_object_from_repo(repoOwner, repoName, file_name);
			total_file_objects.push(out);
		}); // end of forEach
	} else {
		console.log("Repository url:");
		
		// user entered a repository url only
		let url_split = user_input.split("/");
		console.log("url_split:", url_split);
		
		// take last two values of url_split
		let repoName = url_split.pop();
		let repoOwner = url_split.pop();
		console.log("repoName:", repoName);
		console.log("repoOwner:", repoOwner);

		let out = await get_audio_file_objects_from_repo(repoOwner, repoName);
		total_file_objects.push(out);
	}

	return total_file_objects;
}


// ----------------------------------------------------


async function call_custom_model(file_object) {

	document.getElementById('error').innerHTML = 'Model is in development';
}

	
// ----------------------------------------------------

async function start_processing_notification() {
	// Processing information
	document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + 'Processing audio\n';
}

// ----------------------------------------------------


async function call_openai_model_option0(file_object, OPENAI_API_KEY) {
	
	// Read in the mp3 as file_download_url --> convert to  blob_object
	document.getElementById('file_object_name').innerHTML = file_object.name;
	
	console.log("file_object: ", file_object);

	console.log("file_object.download_url: ", file_object.download_url);

	console.log("file_object.name: ", file_object.name);

	await start_processing_notification()
		.then(async function() { let response = await fetch(file_object.download_url); return response; })
		.then(response => response.blob())
		.then(async function(blob_object) { 
			// Transform blob into a file
			return new File ([blob_object], document.getElementById('file_object_name').innerHTML, {type: "audio/mp3"});
		})
		.then(async function(file_blob_object) { 
			// console.log('file_blob_object: ', file_blob_object);
			
			// Use transcription or translation model randomly
			if (Math.floor(Math.random()*2) == 1) {
				await openai_transcription(file_blob_object, 'file_blob_object', document.getElementById('file_object_name').innerHTML, OPENAI_API_KEY);
			} else {
				await openai_translation(file_blob_object, 'file_blob_object', document.getElementById('file_object_name').innerHTML, OPENAI_API_KEY);
			}
		})
		.then(async function() { document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + '\n\nTranscription Processing Done'; })
		.catch(error => { document.getElementById('error').innerHTML = error; });
}


// ----------------------------------------------------


async function call_openai_model_option1(file_object, OPENAI_API_KEY) {
	
	// Read in the mp3 as file_download_url --> convert to  blob_object
	document.getElementById('file_object_name').innerHTML = file_object.name;
	
	console.log("file_object: ", file_object);

	console.log("file_object.base64_string: ", file_object.base64_string);

	console.log("file_object.name: ", file_object.name);

	await start_processing_notification()
		.then(async function() {
			let base64_string = file_object.base64_string;
			// console.log("base64_string: ", base64_string);

			// Follow the process on https://www.base64encode.org/enc/map/, to convert base64_string to ASCII
			
			// Remove header info (mimeString = "audio/mpeg") because atob can not decode data
			const regex = /data:audio\/mpeg;base64,/g;
			base64_string = base64_string.replace(regex, '');
			console.log("base64_string: ", base64_string);
			
			// Decode the Base64-encoded string --> obtain the mp3 data in binary string format
			const binaryString = atob(base64_string);
			console.log("binaryString: ", binaryString);

			// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt
			var character_array = binaryString.split('');
			console.log("character_array: ", character_array);
			
			// Map each binary string character as an ASCII number
			var byteArray = character_array.map((character) => { return character.charCodeAt(0); });
			// console.log("byteArray: ", byteArray);
			// return byteArray;

			// bytes gives the same output as byteArray
			const bytes = new Uint8Array(byteArray);
			console.log("bytes: ", bytes);
			return bytes;
		})
		.then(bytes => { 
			console.log("bytes: ", bytes); 
			// return new Blob(bytes, {type: "audio/mp3"});
			return new Blob(bytes);
		})
		.then(async function(blob_object) { 
			// Transform blob into a file
			return new File ([blob_object], document.getElementById('file_object_name').innerHTML, {type: "audio/mp3"});
		})
		.then(async function(file_blob_object) { 
			// console.log('file_blob_object: ', file_blob_object);
			
			// Use transcription or translation model randomly
			if (Math.floor(Math.random()*2) == 1) {
				await openai_transcription(file_blob_object, 'file_blob_object', document.getElementById('file_object_name').innerHTML, OPENAI_API_KEY);
			} else {
				await openai_translation(file_blob_object, 'file_blob_object', document.getElementById('file_object_name').innerHTML, OPENAI_API_KEY);
			}
		})
		.then(async function() { document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + '\n\nTranscription Processing Done'; })
		.catch(error => { document.getElementById('error').innerHTML = error; });
}

// ----------------------------------------------------


async function openai_transcription(file_input, which_input, header_string, OPENAI_API_KEY) {
	
	const url = 'https://api.openai.com/v1/audio/transcriptions';

	const headers = new Headers();
	headers.append("Authorization", 'Bearer ' + OPENAI_API_KEY);
	headers.append("Accept", "application/json");
	
	const formData = new FormData();
	if (which_input == 'blob_object') {
		formData.append("file", file_input);
	} else {
		// using a file_blob_object
		formData.append("file", file_input, header_string); // mp3, mp4, mpeg, mpga, m4a, wav, or webm
	}
	formData.append("model", "whisper-1");
	formData.append("prompt", "Transcribe the audio");  // Style context for the transcription
	formData.append("response_format", "text");  // json, text, srt, verbose_json, or vtt
	formData.append("temperature", "0");  // The sampling temperature, between 0 (accurate) and 1 (random response)
	formData.append("language", "en");
	formData.append("transcription", "plain text"); // plain text, srt, vtt
	
	const options = {method: 'POST', 
		       headers: headers, 
		       body: formData,
		       redirect: "follow"
		      };
	
	// Print text part of JSON response only with user message
	await fetch(url, options)
		.then(response => response.text())
		.then(async function(result) { 
			document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + `openai_transcription\n${header_string}\n\n${result}\n\n`; 
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}


// ----------------------------------------------------

	
async function openai_translation(file_input, which_input, header_string, OPENAI_API_KEY) {
	
	const url = 'https://api.openai.com/v1/audio/translations';

	const headers = new Headers();
	headers.append("Authorization", 'Bearer ' + OPENAI_API_KEY);
	headers.append("Accept", "application/json");
	
	const formData = new FormData();
	if (which_input == 'blob_object') {
		formData.append("file", file_input);
	} else {
		// using a file_blob_object
		formData.append("file", file_input, header_string); // mp3, mp4, mpeg, mpga, m4a, wav, or webm
	}
	formData.append("model", "whisper-1");
	formData.append("prompt", "Transcribe the audio");  // Style context for the transcription
	formData.append("response_format", "text");  // json, text, srt, verbose_json, or vtt
	formData.append("temperature", "0");  // The sampling temperature, between 0 (accurate) and 1 (random response)
	formData.append("language", "en");
	formData.append("transcription", "plain text"); // plain text, srt, vtt
	
	const options = {method: 'POST', 
		       headers: headers, 
		       body: formData,
		       redirect: "follow"
		      };
	
	// Print text part of JSON response only with user message
	return await fetch(url, options)
		.then(response => response.text())
		.then(async function(result) { 
			document.getElementById('notification').innerHTML = document.getElementById('notification').innerHTML + `openai_translation\n${header_string}\n${result}\n\n`; 
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}

	
// ----------------------------------------------------
	

async function get_one_audio_file_object_from_repo(repoOwner, repoName, file_name) {

	var url = `https://api.github.com/repos/${repoOwner}/${repoName}/contents`;

	let file_objects = [];
	
	return await fetch(url)
		.then(res => res.json())
		.then(data => {
			data.forEach(async function(file) {
				var regexp = new RegExp(`${file_name}`, 'g');
				if (file.type === 'file' && file.name.match(regexp)) {
					file_objects.push(file);
				}
			});
			return file_objects;
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}


// ----------------------------------------------------


async function get_audio_file_objects_from_repo(repoOwner, repoName) {

	var url = `https://api.github.com/repos/${repoOwner}/${repoName}/contents`;
	
	var file_objects = [];
	
	return await fetch(url)
		.then(res => res.json())
		.then(data => {
			data.forEach(async function(file) {
				if (file.type === 'file' && file.name.match(/.(mp3)$/i)) {
					file_objects.push(file);
				}
			});
			return file_objects;
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
	
}


// ----------------------------------------------------
	
</script>

  </body>
</html>
